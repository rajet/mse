{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a8d3d5-6bd3-474a-a599-0694dd5e5906",
   "metadata": {},
   "source": [
    "<img src=\"ost_logo.png\" width=\"240\" height=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Machine Learning </b> <br> MSE FTP MachLe <br> \n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> Christoph WÃ¼rsch </a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc77ad3-6586-4334-b49d-446062b5dbf1",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "Adaped from [D2L.ai: Interactive Deep Learning Book with Multi-Framework Code, Math, and Discussions](https://github.com/d2l-ai/d2l-en/tree/master)\n",
    "\n",
    "In this section we are going to introduce the basic concepts underlying *gradient descent*.\n",
    "Although it is rarely used directly in deep learning, an understanding of gradient descent is key to understanding stochastic gradient descent algorithms. \n",
    "For instance, the optimization problem might diverge due to an overly large learning rate. This phenomenon can already be seen in gradient descent. Likewise, preconditioning is a common technique in gradient descent and carries over to more advanced algorithms.\n",
    "Let us start with a simple special case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5654c16-540e-464c-b333-55aad3d5b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==2.0.0 torchvision==0.15.1\n",
    "# !pip install d2l==1.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f0753-fbef-49ab-aecf-39993db81419",
   "metadata": {},
   "source": [
    "## Derivation of Gradient Descent Rule Using Quadratic Approximation\n",
    "\n",
    "In this derivation, we will use a quadratic approximation of the objective function to derive the gradient descent update rule.\n",
    "Given an objective function $f(x)$, we seek to iteratively update $x$ such that $f(x)$ decreases. At each step, we can approximate $f(x)$ around the current point $x_t$ using a first-order Taylor expansion:\n",
    "\n",
    "$$\n",
    "f(x_{t+1}) \\approx f(x_t) + \\nabla f(x_t)^T (x_{t+1} - x_t).\n",
    "$$\n",
    "\n",
    "To simplify this notation, define the step update $\\Delta x_t = x_{t+1} - x_t$. This leads to the following approximation:\n",
    "\n",
    "$$\n",
    "f(x_{t+1}) \\approx f(x_t) + \\nabla f(x_t)^T \\Delta x_t.\n",
    "$$\n",
    "\n",
    "At this point, we want to minimize this approximation. However, we must prevent the update $\\Delta x_t$ from being too large, which could lead to divergence. Therefore, we add a quadratic penalty to the step size to control the size of $\\Delta x_t$. The resulting minimization problem is:\n",
    "\n",
    "$$\n",
    "\\min_{\\Delta x_t} \\left[ f(x_t) + \\nabla f(x_t)^T \\Delta x_t + \\frac{1}{2\\eta} \\|\\Delta x_t\\|^2 \\right].\n",
    "$$\n",
    "\n",
    "Here, $\\eta > 0$ is a step size parameter that controls how large a step we take.\n",
    "\n",
    "### Minimizing the Quadratic Approximation\n",
    "\n",
    "To find the update $\\Delta x_t$, we take the gradient of the objective function with respect to $\\Delta x_t$ and set it to zero:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\Delta x_t} \\left[ \\nabla f(x_t)^T \\Delta x_t + \\frac{1}{2\\eta} \\|\\Delta x_t\\|^2 \\right] = 0.\n",
    "$$\n",
    "\n",
    "This results in the following equation:\n",
    "\n",
    "$$\n",
    "\\nabla f(x_t) + \\frac{1}{\\eta} \\Delta x_t = 0.\n",
    "$$\n",
    "\n",
    "Solving for $\\Delta x_t$, we obtain:\n",
    "\n",
    "$$\n",
    "\\Delta x_t = -\\eta \\nabla f(x_t).\n",
    "$$\n",
    "\n",
    "Thus, the gradient descent rule can be derived by minimizing the quadratic approximation of the objective function at each iteration, leading to the following update rule:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "x_{t+1} = x_t - \\eta \\nabla f(x_t)}\n",
    "$$\n",
    "\n",
    "where $\\eta$ is the step size (learning rate), and $\\nabla f(x_t)$ is the gradient of the function at the current point $x_t$.\n",
    "\n",
    "### Example: Gradient Descent on $f(x) = (x - 2)^2 + 3 + 5 \\sin(x)$\n",
    "\n",
    "To illustrate this algorithm, let's apply gradient descent to minimize the function $f(x) = (x - 2)^2 + 3+5\\sin(x)$. The global minimum is approximately at $x = 2$, and we can use the following Python implementation to visualize how gradient descent converges to this point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018bb81f-cc73-4c87-a089-ed4f25b3a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the objective function and its derivative\n",
    "def f(x):\n",
    "    return (x-2)**2 + 3 + 5*np.sin(x)\n",
    "\n",
    "def f_prime(x):\n",
    "    return 2*(x-2)+5*np.cos(x)\n",
    "\n",
    "# Gradient descent algorithm\n",
    "def gradient_descent(x0, eta, iterations):\n",
    "    x_values = [x0]\n",
    "    for _ in range(iterations):\n",
    "        x0 = x0 - eta * f_prime(x0)\n",
    "        x_values.append(x0)\n",
    "    return x_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14439153-b498-49e7-abea-faa4a98a2bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters\n",
    "x0 = 10  # Initial starting point\n",
    "eta = 0.1  # Step size (learning rate)\n",
    "iterations = 30  # Number of iterations\n",
    "\n",
    "# Perform gradient descent\n",
    "x_values = gradient_descent(x0, eta, iterations)\n",
    "\n",
    "# Generate data for plotting the function\n",
    "x = np.linspace(-2, 12, 100)\n",
    "y = f(x)\n",
    "\n",
    "# Plot the function and the gradient descent steps\n",
    "plt.plot(x, y, label='$f(x) = (x-2)^2 + 3$', color='blue')\n",
    "plt.plot(x_values, f(np.array(x_values)), 'ro-', label='Gradient Descent Steps', markersize=5)\n",
    "plt.title('Gradient Descent on $f(x) = (x-2)^2 + 3$')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3574686",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "The optimization problem might diverge due to an overly large learning rate. This phenomenon can already be seen in gradient descent. Likewise, preconditioning is a common technique in gradient descent and carries over to more advanced algorithms.\n",
    "Let's start with a simple special case. This means that, if we use\n",
    "\n",
    "$$x \\leftarrow x - \\eta f'(x)$$\n",
    "\n",
    "to iterate $x$, the value of function $f(x)$ might decline. Therefore, in gradient descent we first choose an initial value $x$ and a constant $\\eta > 0$ and then use them to continuously iterate $x$ until the stop condition is reached, for example, when the magnitude of the gradient $|f'(x)|$ is small enough or the number of iterations has reached a certain value.\n",
    "\n",
    "For simplicity we choose the objective function $f(x)=x^2$ to illustrate how to implement gradient descent. Although we know that $x=0$ is the solution to minimize $f(x)$, we still use this simple function to observe how $x$ changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f537297a",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01md2l\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m torch \u001b[38;5;28;01mas\u001b[39;00m d2l\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ceef0",
   "metadata": {
    "origin_pos": 4,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def f(x):  # Objective function\n",
    "    return x ** 2\n",
    "\n",
    "def f_grad(x):  # Gradient (derivative) of the objective function\n",
    "    return 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3056a88",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "Next, we use $x=10$ as the initial value and assume $\\eta=0.2$. Using gradient descent to iterate $x$ for 10 times we can see that, eventually, the value of $x$ approaches the optimal solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422133ef",
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def gd(eta, f_grad):\n",
    "    x = 10.0\n",
    "    results = [x]\n",
    "    for i in range(10):\n",
    "        x -= eta * f_grad(x)\n",
    "        results.append(float(x))\n",
    "    print(f'epoch 10, x: {x:f}')\n",
    "    return results\n",
    "\n",
    "results = gd(0.2, f_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaee2bb",
   "metadata": {
    "origin_pos": 7
   },
   "source": [
    "The progress of optimizing over $x$ can be plotted as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e2000",
   "metadata": {
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def show_trace(results, f):\n",
    "    n = max(abs(min(results)), abs(max(results)))\n",
    "    f_line = torch.arange(-n, n, 0.01)\n",
    "    d2l.set_figsize()\n",
    "    d2l.plot([f_line, results], [[f(x) for x in f_line], [\n",
    "        f(x) for x in results]], 'x', 'f(x)', fmts=['-', '-o'])\n",
    "\n",
    "show_trace(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ff902",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "### Learning Rate\n",
    ":label:`subsec_gd-learningrate`\n",
    "\n",
    "The learning rate $\\eta$ can be set by the algorithm designer. If we use a learning rate that is too small, it will cause $x$ to update very slowly, requiring more iterations to get a better solution. To show what happens in such a case, consider the progress in the same optimization problem for $\\eta = 0.05$. As we can see, even after 10 steps we are still very far from the optimal solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44db8c3",
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "show_trace(gd(0.05, f_grad), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6180e1",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "Conversely, if we use an excessively high learning rate, $\\left|\\eta f'(x)\\right|$ might be too large for the first-order Taylor expansion formula. That is, the term $\\mathcal{O}(\\eta^2 f'^2(x))$ in :eqref:`gd-taylor-2` might become significant. In this case, we cannot guarantee that the iteration of $x$ will be able to lower the value of $f(x)$. For example, when we set the learning rate to $\\eta=1.1$, $x$ overshoots the optimal solution $x=0$ and gradually diverges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8495ce",
   "metadata": {
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "show_trace(gd(1.1, f_grad), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64969e8b",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "### Local Minima\n",
    "\n",
    "To illustrate what happens for nonconvex functions consider the case of $f(x) = x \\cdot \\cos(cx)$ for some constant $c$. This function has infinitely many local minima. Depending on our choice of the learning rate and depending on how well conditioned the problem is, we may end up with one of many solutions. The example below illustrates how an (unrealistically) high learning rate will lead to a poor local minimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5974ec6",
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "c = torch.tensor(0.15 * np.pi)\n",
    "\n",
    "def f(x):  # Objective function\n",
    "    return x * torch.cos(c * x)\n",
    "\n",
    "def f_grad(x):  # Gradient of the objective function\n",
    "    return torch.cos(c * x) - c * x * torch.sin(c * x)\n",
    "\n",
    "show_trace(gd(2, f_grad), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb81605",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "## Multivariate Gradient Descent\n",
    "\n",
    "Now that we have a better intuition of the univariate case, let's consider the situation where $\\mathbf{x} = [x_1, x_2, \\ldots, x_d]^\\top$. That is, the objective function $f: \\mathbb{R}^d \\to \\mathbb{R}$ maps vectors into scalars. Correspondingly its gradient is multivariate, too. It is a vector consisting of $d$ partial derivatives:\n",
    "\n",
    "$$\\nabla f(\\mathbf{x}) = \\bigg[\\frac{\\partial f(\\mathbf{x})}{\\partial x_1}, \\frac{\\partial f(\\mathbf{x})}{\\partial x_2}, \\ldots, \\frac{\\partial f(\\mathbf{x})}{\\partial x_d}\\bigg]^\\top.$$\n",
    "\n",
    "Each partial derivative element $\\partial f(\\mathbf{x})/\\partial x_i$ in the gradient indicates the rate of change of $f$ at $\\mathbf{x}$ with respect to the input $x_i$. As before in the univariate case we can use the corresponding Taylor approximation for multivariate functions to get some idea of what we should do. In particular, we have that\n",
    "\n",
    "$$f(\\mathbf{x} + \\boldsymbol{\\epsilon}) = f(\\mathbf{x}) + \\mathbf{\\boldsymbol{\\epsilon}}^\\top \\nabla f(\\mathbf{x}) + \\mathcal{O}(\\|\\boldsymbol{\\epsilon}\\|^2).$$\n",
    ":eqlabel:`gd-multi-taylor`\n",
    "\n",
    "In other words, up to second-order terms in $\\boldsymbol{\\epsilon}$ the direction of steepest descent is given by the negative gradient $-\\nabla f(\\mathbf{x})$. Choosing a suitable learning rate $\\eta > 0$ yields the prototypical gradient descent algorithm:\n",
    "\n",
    "$$\\mathbf{x} \\leftarrow \\mathbf{x} - \\eta \\nabla f(\\mathbf{x}).$$\n",
    "\n",
    "To see how the algorithm behaves in practice let's construct an objective function $f(\\mathbf{x})=x_1^2+2x_2^2$ with a two-dimensional vector $\\mathbf{x} = [x_1, x_2]^\\top$ as input and a scalar as output. The gradient is given by $\\nabla f(\\mathbf{x}) = [2x_1, 4x_2]^\\top$. We will observe the trajectory of $\\mathbf{x}$ by gradient descent from the initial position $[-5, -2]$.\n",
    "\n",
    "To begin with, we need two more helper functions. The first uses an update function and applies it 20 times to the initial value. The second helper visualizes the trajectory of $\\mathbf{x}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18511caf",
   "metadata": {
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def train_2d(trainer, steps=20, f_grad=None):  #@save\n",
    "    \"\"\"Optimize a 2D objective function with a customized trainer.\"\"\"\n",
    "    # `s1` and `s2` are internal state variables that will be used in Momentum, adagrad, RMSProp\n",
    "    x1, x2, s1, s2 = -5, -2, 0, 0\n",
    "    results = [(x1, x2)]\n",
    "    for i in range(steps):\n",
    "        if f_grad:\n",
    "            x1, x2, s1, s2 = trainer(x1, x2, s1, s2, f_grad)\n",
    "        else:\n",
    "            x1, x2, s1, s2 = trainer(x1, x2, s1, s2)\n",
    "        results.append((x1, x2))\n",
    "    print(f'epoch {i + 1}, x1: {float(x1):f}, x2: {float(x2):f}')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e4411",
   "metadata": {
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def show_trace_2d(f, results):  #@save\n",
    "    \"\"\"Show the trace of 2D variables during optimization.\"\"\"\n",
    "    d2l.set_figsize()\n",
    "    d2l.plt.plot(*zip(*results), '-o', color='#ff7f0e')\n",
    "    x1, x2 = torch.meshgrid(torch.arange(-5.5, 1.0, 0.1),\n",
    "                          torch.arange(-3.0, 1.0, 0.1), indexing='ij')\n",
    "    d2l.plt.contour(x1, x2, f(x1, x2), colors='#1f77b4')\n",
    "    d2l.plt.xlabel('x1')\n",
    "    d2l.plt.ylabel('x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3958c101",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "Next, we observe the trajectory of the optimization variable $\\mathbf{x}$ for learning rate $\\eta = 0.1$. We can see that after 20 steps the value of $\\mathbf{x}$ approaches its minimum at $[0, 0]$. Progress is fairly well-behaved albeit rather slow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c065f",
   "metadata": {
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def f_2d(x1, x2):  # Objective function\n",
    "    return x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "def f_2d_grad(x1, x2):  # Gradient of the objective function\n",
    "    return (2 * x1, 4 * x2)\n",
    "\n",
    "def gd_2d(x1, x2, s1, s2, f_grad):\n",
    "    g1, g2 = f_grad(x1, x2)\n",
    "    return (x1 - eta * g1, x2 - eta * g2, 0, 0)\n",
    "\n",
    "eta = 0.1\n",
    "show_trace_2d(f_2d, train_2d(gd_2d, f_grad=f_2d_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ada6e5",
   "metadata": {
    "origin_pos": 22
   },
   "source": [
    "## Adaptive Methods\n",
    "\n",
    "As we could see in :numref:`subsec_gd-learningrate`, getting the learning rate $\\eta$ \"just right\" is tricky. If we pick it too small, we make little progress. If we pick it too large, the solution oscillates and in the worst case it might even diverge. What if we could determine $\\eta$ automatically or get rid of having to select a learning rate at all?\n",
    "Second-order methods that look not only at the value and gradient of the objective function\n",
    "but also at its *curvature* can help in this case. While these methods cannot be applied to deep learning directly due to the computational cost, they provide useful intuition into how to design advanced optimization algorithms that mimic many of the desirable properties of the algorithms outlined below.\n",
    "\n",
    "\n",
    "### Newton's Method\n",
    "\n",
    "Reviewing the Taylor expansion of some function $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}$ there is no need to stop after the first term. In fact, we can write it as\n",
    "\n",
    "$$f(\\mathbf{x} + \\boldsymbol{\\epsilon}) = f(\\mathbf{x}) + \\boldsymbol{\\epsilon}^\\top \\nabla f(\\mathbf{x}) + \\frac{1}{2} \\boldsymbol{\\epsilon}^\\top \\nabla^2 f(\\mathbf{x}) \\boldsymbol{\\epsilon} + \\mathcal{O}(\\|\\boldsymbol{\\epsilon}\\|^3).$$\n",
    ":eqlabel:`gd-hot-taylor`\n",
    "\n",
    "To avoid cumbersome notation we define $\\mathbf{H} \\stackrel{\\textrm{def}}{=} \\nabla^2 f(\\mathbf{x})$ to be the Hessian of $f$, which is a $d \\times d$ matrix. For small $d$ and simple problems $\\mathbf{H}$ is easy to compute. For deep neural networks, on the other hand, $\\mathbf{H}$ may be prohibitively large, due to the cost of storing $\\mathcal{O}(d^2)$ entries. Furthermore it may be too expensive to compute via backpropagation. For now let's ignore such considerations and look at what algorithm we would get.\n",
    "\n",
    "After all, the minimum of $f$ satisfies $\\nabla f = 0$.\n",
    "Following calculus rules in :numref:`subsec_calculus-grad`,\n",
    "by taking derivatives of :eqref:`gd-hot-taylor` with regard to $\\boldsymbol{\\epsilon}$ and ignoring higher-order terms we arrive at\n",
    "\n",
    "$$\\nabla f(\\mathbf{x}) + \\mathbf{H} \\boldsymbol{\\epsilon} = 0 \\textrm{ and hence }\n",
    "\\boldsymbol{\\epsilon} = -\\mathbf{H}^{-1} \\nabla f(\\mathbf{x}).$$\n",
    "\n",
    "That is, we need to invert the Hessian $\\mathbf{H}$ as part of the optimization problem.\n",
    "\n",
    "As a simple example, for $f(x) = \\frac{1}{2} x^2$ we have $\\nabla f(x) = x$ and $\\mathbf{H} = 1$. Hence for any $x$ we obtain $\\epsilon = -x$. In other words, a *single* step is sufficient to converge perfectly without the need for any adjustment! Alas, we got a bit lucky here: the Taylor expansion was exact since $f(x+\\epsilon)= \\frac{1}{2} x^2 + \\epsilon x + \\frac{1}{2} \\epsilon^2$.\n",
    "\n",
    "Let's see what happens in other problems.\n",
    "Given a convex hyperbolic cosine function $f(x) = \\cosh(cx)$ for some constant $c$, we can see that\n",
    "the global minimum at $x=0$ is reached\n",
    "after a few iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc7fa71",
   "metadata": {
    "origin_pos": 23,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "c = torch.tensor(0.5)\n",
    "\n",
    "def f(x):  # Objective function\n",
    "    return torch.cosh(c * x)\n",
    "\n",
    "def f_grad(x):  # Gradient of the objective function\n",
    "    return c * torch.sinh(c * x)\n",
    "\n",
    "def f_hess(x):  # Hessian of the objective function\n",
    "    return c**2 * torch.cosh(c * x)\n",
    "\n",
    "def newton(eta=1):\n",
    "    x = 10.0\n",
    "    results = [x]\n",
    "    for i in range(10):\n",
    "        x -= eta * f_grad(x) / f_hess(x)\n",
    "        results.append(float(x))\n",
    "    print('epoch 10, x:', x)\n",
    "    return results\n",
    "\n",
    "show_trace(newton(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0391ca08",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "Now let's consider a *nonconvex* function, such as $f(x) = x \\cos(c x)$ for some constant $c$. After all, note that in Newton's method we end up dividing by the Hessian. This means that if the second derivative is *negative* we may walk into the direction of *increasing* the value of $f$.\n",
    "That is a fatal flaw of the algorithm.\n",
    "Let's see what happens in practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe75765",
   "metadata": {
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "c = torch.tensor(0.15 * np.pi)\n",
    "\n",
    "def f(x):  # Objective function\n",
    "    return x * torch.cos(c * x)\n",
    "\n",
    "def f_grad(x):  # Gradient of the objective function\n",
    "    return torch.cos(c * x) - c * x * torch.sin(c * x)\n",
    "\n",
    "def f_hess(x):  # Hessian of the objective function\n",
    "    return - 2 * c * torch.sin(c * x) - x * c**2 * torch.cos(c * x)\n",
    "\n",
    "show_trace(newton(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0843c5c1",
   "metadata": {
    "origin_pos": 26
   },
   "source": [
    "This went spectacularly wrong. How can we fix it? One way would be to \"fix\" the Hessian by taking its absolute value instead. Another strategy is to bring back the learning rate. This seems to defeat the purpose, but not quite. Having second-order information allows us to be cautious whenever the curvature is large and to take longer steps whenever the objective function is flatter.\n",
    "Let's see how this works with a slightly smaller learning rate, say $\\eta = 0.5$. As we can see, we have quite an efficient algorithm.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
