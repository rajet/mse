{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_KBxaU7kdaL"
   },
   "source": [
    "# Decision Trees and Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0t5EknLAQuX_"
   },
   "source": [
    "## Exercise: Decision Trees\n",
    "\n",
    "We are going to use the breast cancer dataset from sklearn where the goal is to classify each sample as malignant or benign (binary classification task) based on features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3994,
     "status": "ok",
     "timestamp": 1601993944723,
     "user": {
      "displayName": "Helmut Grabner",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7VFoSO9VR3VvyyTFY2VEA3A1vWKRswaJHGQ3HoA=s64",
      "userId": "06526771998566964714"
     },
     "user_tz": -120
    },
    "id": "Cz9Q5e0AQvma",
    "outputId": "1a877bd8-43ae-4fbf-dfdd-7c45bcbb12c3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "plt.figure(figsize=(30,30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model fitting\n",
    "\n",
    "In this exercise you need to do the following:\n",
    "- Split the data into a training and a test set using test size of 30% of the training set.\n",
    "\n",
    "- Train a decision tree classifier to the data and visualize it.\n",
    "\n",
    "- Make a prediction for the test set\n",
    "\n",
    "- Evaluate the model's performance by computing the accuracy score and plotting the confusion matrix. \n",
    "\n",
    "#### Hints: \n",
    "Decision Trees: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "Tree Plot: https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html\n",
    "\n",
    "Confusion matrix plot: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Apply a decisiontree classifier to the data and visualize your decision tree\n",
    "#### START YOUR SOLUTION HERE ####\n",
    "# Split the data into training and test set\n",
    "\n",
    "# fit model \n",
    "\n",
    "# Plot the fitted tree\n",
    "\n",
    "# compute predictions for test set\n",
    "\n",
    "# Compute the accuracy score\n",
    "\n",
    "# Compute the confusion matrix\n",
    "\n",
    "# Plot the confusion matrix\n",
    "\n",
    "#### END YOUR SOLUTION HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning tree depth with grid search CV\n",
    "Tune the tree depth parameter using grid seacrh cross validation. Check out depth values between 1 and 10. \n",
    "- What is the optimal tree depth and its corresponding test accuracy score?\n",
    "\n",
    "- Plot the tree with the optimal depth parameter.\n",
    "\n",
    "- What is the CV accuracy for the best parameter (tree depth)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search - tuning tree depth\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#### START YOUR SOLUTION HERE ####\n",
    "# Define grid for the parameter to test - max_depth from 1 to 10\n",
    "\n",
    "# Define and fit model using grid search CV with 5-fold cross validation\n",
    "\n",
    "# Plot the fitted tree\n",
    "\n",
    "# Print results\n",
    "\n",
    "#### END YOUR SOLUTION HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lzl9ZvCDkdaO"
   },
   "source": [
    "## Exercise: Random Forest\n",
    "Now we train a random forest model to the same dataset (for the same task) using the same training test split.\n",
    "- Apply a random forest classifier with 100 trees to the data.\n",
    "- Compute and print the training and test accuracies and compare it to the out of bag score (hint: set `oob_score = True` in classifier).\n",
    "\n",
    "#### Hints:\n",
    "Random Forest: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "OOB: https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "executionInfo": {
     "elapsed": 1853,
     "status": "ok",
     "timestamp": 1601993960827,
     "user": {
      "displayName": "Helmut Grabner",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7VFoSO9VR3VvyyTFY2VEA3A1vWKRswaJHGQ3HoA=s64",
      "userId": "06526771998566964714"
     },
     "user_tz": -120
    },
    "id": "GiiWbrqakdaP",
    "outputId": "5424ded7-bd62-4fb3-a062-573f7b464a4a"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "#### END YOUR SOLUTION HERE ####\n",
    "# fit model \n",
    "\n",
    "# compute predictions for the training and test sets\n",
    "\n",
    "# compute the accuracy scores (test, training and OOB)\n",
    "\n",
    "\n",
    "# print the computed scores\n",
    "\n",
    "# Compute the confusion matrix\n",
    "\n",
    "# Plot the confusion matrix \n",
    "\n",
    "#### END YOUR SOLUTION HERE ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the number of trees parameter using grid search\n",
    "\n",
    "Use grid search CV (5 folds) to find the best number of treees (estimators) using a grid from 100 to 1000 with a step of 100. Print the best number of trees and its corresponding test accuracy score and cross validation accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### START YOUR SOLUTION HERE ####\n",
    "# Define the grid for the number of trees\n",
    "\n",
    "# Do a grid search to find the optimal number of trees\n",
    "\n",
    "# print the best hyperparameter\n",
    "\n",
    "# print the training CV accuracy score\n",
    "\n",
    "# print the test accuracy score\n",
    "\n",
    "#### END YOUR SOLUTION HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsFsLIQ_kdaS"
   },
   "source": [
    "### Importance plot\n",
    "Use the permutation importance to compute the feature importances for the best model from the grid search CV. \n",
    "\n",
    "#### Hints:\n",
    "Forest importances: https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "executionInfo": {
     "elapsed": 2163,
     "status": "ok",
     "timestamp": 1601993971506,
     "user": {
      "displayName": "Helmut Grabner",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7VFoSO9VR3VvyyTFY2VEA3A1vWKRswaJHGQ3HoA=s64",
      "userId": "06526771998566964714"
     },
     "user_tz": -120
    },
    "id": "HAJD2puMkdaT",
    "outputId": "039c7342-f273-4ba8-cdf2-0a12d62aedc8"
   },
   "outputs": [],
   "source": [
    "# retrieve the relative importance of each variable and visualize the importance plot\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#### START YOUR SOLUTION HERE ####\n",
    "# get the best model from the grid search CV\n",
    "\n",
    "# compute the feature importances using permutation test\n",
    "\n",
    "# sort them\n",
    "\n",
    "# plot the importances\n",
    "\n",
    "#### END YOUR SOLUTION HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we use the attribute `feature_importances_` of random forest model selected in the grid search that quantifies the feature importance based on mean decrease in impurity. These scores, however, can be misleading for continuous and high cardinality features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the feature importances from the fitted model\n",
    "importances = best_rf_model.feature_importances_\n",
    "# get the standard deviations\n",
    "std = np.std([tree.feature_importances_ for tree in best_rf_model.estimators_], axis=0)\n",
    "# put them in pandas series\n",
    "forest_importances = pd.Series(importances, index=cancer.feature_names)\n",
    "# sort them\n",
    "forest_importances.sort_values(inplace=True, ascending=False)\n",
    "\n",
    "# plot them\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "P04 Trees and Forests (Solution).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
